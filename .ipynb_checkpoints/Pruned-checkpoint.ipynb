{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **M.Tech Master's Thesis Project (MTP-2)**  \n",
    "### **Tushar Kanwaria**  \n",
    "### **Roll No: 20EC39037**  \n",
    "### **Electronics and Electrical Communication Engineering Department**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying and visualiazing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping D:\\Downloads\\MTP-2\\MTP-2\\BBBC007_v1_images\\BBBC007_v1_images\\f96 (17), path not found.\n",
      "Skipping D:\\Downloads\\MTP-2\\MTP-2\\BBBC007_v1_outlines\\BBBC007_v1_outlines\\f96 (17), path not found.\n",
      "Skipping D:\\Downloads\\MTP-2\\MTP-2\\BBBC007_v1_images\\BBBC007_v1_images\\A9, path not found.\n",
      "Skipping D:\\Downloads\\MTP-2\\MTP-2\\BBBC007_v1_outlines\\BBBC007_v1_outlines\\A9, path not found.\n",
      "Skipping D:\\Downloads\\MTP-2\\MTP-2\\BBBC008_v1_foreground\\human_ht29_colon_cancer_2_foreground, path not found.\n",
      "Skipping D:\\Downloads\\MTP-2\\MTP-2\\BBBC008_v1_images\\human_ht29_colon_cancer_2_images, path not found.\n",
      "Skipping D:\\Downloads\\MTP-2\\MTP-2\\BBBC010_v1_foreground\\BBBC010_v1_foreground, path not found.\n",
      "Skipping D:\\Downloads\\MTP-2\\MTP-2\\BBBC010_v2_images, path not found.\n",
      "Skipping D:\\Downloads\\MTP-2\\MTP-2\\data-science-bowl-2018\\stage1_train\\00ae65c1c6631ae6f2be1a449902976e6eb8483bf6b0740d00530220832c6d3e\\images, path not found.\n",
      "Skipping D:\\Downloads\\MTP-2\\MTP-2\\data-science-bowl-2018\\stage1_train\\00ae65c1c6631ae6f2be1a449902976e6eb8483bf6b0740d00530220832c6d3e\\masks, path not found.\n",
      "Skipping D:\\Downloads\\MTP-2\\MTP-2\\kmms_test\\kmms_test\\images, path not found.\n",
      "Skipping D:\\Downloads\\MTP-2\\MTP-2\\kmms_test\\kmms_test\\masks, path not found.\n",
      "Skipping D:\\Downloads\\MTP-2\\MTP-2\\kmms_training\\kmms_training\\images, path not found.\n",
      "Skipping D:\\Downloads\\MTP-2\\MTP-2\\kmms_training\\kmms_training\\masks, path not found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "try:\n",
    "    import cairosvg\n",
    "    svg_support = True\n",
    "except ImportError:\n",
    "    svg_support = False\n",
    "\n",
    "base_dirs = [\n",
    "    r\"D:\\Downloads\\MTP-2\\MTP-2\\BBBC007_v1_images\\BBBC007_v1_images\\f96 (17)\",\n",
    "    r\"D:\\Downloads\\MTP-2\\MTP-2\\BBBC007_v1_outlines\\BBBC007_v1_outlines\\f96 (17)\",\n",
    "    r\"D:\\Downloads\\MTP-2\\MTP-2\\BBBC007_v1_images\\BBBC007_v1_images\\A9\",\n",
    "    r\"D:\\Downloads\\MTP-2\\MTP-2\\BBBC007_v1_outlines\\BBBC007_v1_outlines\\A9\",\n",
    "    r\"D:\\Downloads\\MTP-2\\MTP-2\\BBBC008_v1_foreground\\human_ht29_colon_cancer_2_foreground\",\n",
    "    r\"D:\\Downloads\\MTP-2\\MTP-2\\BBBC008_v1_images\\human_ht29_colon_cancer_2_images\",\n",
    "    r\"D:\\Downloads\\MTP-2\\MTP-2\\BBBC010_v1_foreground\\BBBC010_v1_foreground\",\n",
    "    r\"D:\\Downloads\\MTP-2\\MTP-2\\BBBC010_v2_images\",\n",
    "    r\"D:\\Downloads\\MTP-2\\MTP-2\\data-science-bowl-2018\\stage1_train\\00ae65c1c6631ae6f2be1a449902976e6eb8483bf6b0740d00530220832c6d3e\\images\",\n",
    "    r\"D:\\Downloads\\MTP-2\\MTP-2\\data-science-bowl-2018\\stage1_train\\00ae65c1c6631ae6f2be1a449902976e6eb8483bf6b0740d00530220832c6d3e\\masks\",\n",
    "    r\"D:\\Downloads\\MTP-2\\MTP-2\\kmms_test\\kmms_test\\images\",\n",
    "    r\"D:\\Downloads\\MTP-2\\MTP-2\\kmms_test\\kmms_test\\masks\",\n",
    "    r\"D:\\Downloads\\MTP-2\\MTP-2\\kmms_training\\kmms_training\\images\",\n",
    "    r\"D:\\Downloads\\MTP-2\\MTP-2\\kmms_training\\kmms_training\\masks\"\n",
    "]\n",
    "BASE_DIR = r\"D:\\codes\\CNN\"\n",
    "\n",
    "image_extensions = ('*.png', '*.jpg', '*.jpeg', '*.svg', '*.tif', '*.tiff')\n",
    "\n",
    "for base_dir in base_dirs:\n",
    "    if not os.path.exists(base_dir):\n",
    "        print(f\"Skipping {base_dir}, path not found.\")\n",
    "        continue\n",
    "\n",
    "    image_files = []\n",
    "    for ext in image_extensions:\n",
    "        image_files.extend(glob.glob(os.path.join(base_dir, ext)))\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No images found in {base_dir}\")\n",
    "        continue\n",
    "\n",
    "    image_files = image_files[:5]  # Limit to 5 images\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(image_files), figsize=(len(image_files) * 3, 5))\n",
    "    plt.subplots_adjust(top=0.75)  # Adjust spacing for title visibility\n",
    "\n",
    "    plt.figtext(0.5, 0.9, f\"Folder: {os.path.basename(base_dir)}\", fontsize=14, fontweight=\"bold\", ha=\"center\")\n",
    "    plt.figtext(0.5, 0.85, f\"Path: {base_dir}\", fontsize=12, ha=\"center\", wrap=True)\n",
    "\n",
    "    if len(image_files) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, file_path in enumerate(image_files):\n",
    "        file_ext = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "        if file_ext == \".svg\" and svg_support:\n",
    "            png_data = cairosvg.svg2png(url=file_path)\n",
    "            img = Image.open(io.BytesIO(png_data))\n",
    "        else:\n",
    "            img = Image.open(file_path)\n",
    "\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage distribution (exclugind masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Downloads\\\\MTP-2\\\\MTP-2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m excluded_folders \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmasks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBBBC010_v1_foreground_eachworm\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      9\u001b[0m folder_counts \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subfolder \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(base_dir):\n\u001b[1;32m     12\u001b[0m     subfolder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, subfolder)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(subfolder_path) \u001b[38;5;129;01mor\u001b[39;00m subfolder \u001b[38;5;129;01min\u001b[39;00m excluded_folders:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Downloads\\\\MTP-2\\\\MTP-2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "BASE_DIR = r\"D:\\code\\CNN\"\n",
    "# base_dir = r\"D:\\Downloads\\MTP-2\\MTP-2\"\n",
    "image_extensions = ('*.png', '*.jpg', '*.jpeg', '*.svg', '*.tif', '*.tiff')\n",
    "\n",
    "excluded_folders = {\"masks\", \"BBBC010_v1_foreground_eachworm\"}\n",
    "folder_counts = {}\n",
    "\n",
    "for subfolder in os.listdir(base_dir):\n",
    "    subfolder_path = os.path.join(base_dir, subfolder)\n",
    "\n",
    "    if not os.path.isdir(subfolder_path) or subfolder in excluded_folders:\n",
    "        continue\n",
    "\n",
    "    image_count = 0\n",
    "    for root, _, files in os.walk(subfolder_path):\n",
    "        if any(excl in root for excl in excluded_folders):\n",
    "            continue\n",
    "\n",
    "        for ext in image_extensions:\n",
    "            image_count += len(glob.glob(os.path.join(root, ext)))\n",
    "\n",
    "    folder_counts[subfolder] = image_count\n",
    "\n",
    "folder_counts = {k: v for k, v in folder_counts.items() if v > 0}\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pie(folder_counts.values(), labels=folder_counts.keys(), autopct=\"%1.1f%%\", colors=plt.cm.Paired.colors, startangle=140)\n",
    "plt.title(\"Percentage of Image Files in Each Subfolder\", fontsize=14, fontweight=\"bold\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model and mentioning eval metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import os\n",
    "    import glob\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers, Model\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "\n",
    "\n",
    "    def iou(y_true, y_pred, smooth=1e-6):\n",
    "        \"\"\"Intersection over Union (IoU) metric.\"\"\"\n",
    "        y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "        intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "        union = tf.reduce_sum(y_true + y_pred, axis=[1, 2, 3]) - intersection\n",
    "        return tf.reduce_mean((intersection + smooth) / (union + smooth))\n",
    "\n",
    "    def dice(y_true, y_pred, smooth=1e-6):\n",
    "        \"\"\"Dice coefficient (DSC) metric.\"\"\"\n",
    "        y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "        intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "        return tf.reduce_mean((2. * intersection + smooth) /\n",
    "                            (tf.reduce_sum(y_true, axis=[1, 2, 3]) +\n",
    "                            tf.reduce_sum(y_pred, axis=[1, 2, 3]) + smooth))\n",
    "\n",
    "    def precision(y_true, y_pred, smooth=1e-6):\n",
    "        \"\"\"Precision metric.\"\"\"\n",
    "        y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "        predicted_positives = tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "        return tf.reduce_mean(true_positives / (predicted_positives + smooth))\n",
    "\n",
    "    def recall(y_true, y_pred, smooth=1e-6):\n",
    "        \"\"\"Recall metric.\"\"\"\n",
    "        y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "        true_positives = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "        actual_positives = tf.reduce_sum(y_true, axis=[1, 2, 3])\n",
    "        return tf.reduce_mean(true_positives / (actual_positives + smooth))\n",
    "\n",
    "\n",
    "    # Again defining the model, first we analyzed now we will use it to train\n",
    "    def light_unet(input_shape=(256, 256, 3)):\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "        # -------- Encoder --------\n",
    "        x1 = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "        x1 = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x1)\n",
    "        p1 = layers.MaxPooling2D((2, 2))(x1)\n",
    "\n",
    "        x2 = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(p1)\n",
    "        x2 = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x2)\n",
    "        p2 = layers.MaxPooling2D((2, 2))(x2)\n",
    "\n",
    "        x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(p2)\n",
    "        x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "\n",
    "        # -------- Decoder --------\n",
    "        x = layers.UpSampling2D((2, 2))(x)\n",
    "        x = layers.Concatenate()([x, x2])\n",
    "        x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "        x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "\n",
    "        x = layers.UpSampling2D((2, 2))(x)\n",
    "        x = layers.Concatenate()([x, x1])\n",
    "        x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "        x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "\n",
    "        # -------- Output --------\n",
    "        outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(x)\n",
    "\n",
    "        model = Model(inputs, outputs)\n",
    "        return model\n",
    "    model = light_unet()\n",
    "    model.summary()\n",
    "\n",
    "    # Data Loading and Preprocessing\n",
    "    image_dir = r\"D:\\Downloads\\MTP-2\\unified_dataset\\images\"\n",
    "    mask_dir  = r\"D:\\Downloads\\MTP-2\\unified_dataset\\masks\"\n",
    "\n",
    "    image_files = sorted(glob.glob(os.path.join(image_dir, \"*.png\")))\n",
    "    mask_files  = sorted(glob.glob(os.path.join(mask_dir, \"*.png\")))\n",
    "\n",
    "    if len(image_files) != len(mask_files):\n",
    "        raise ValueError(\"The number of images and masks does not match. Check your dataset.\")\n",
    "\n",
    "    def process_path(image_path, mask_path, img_size=(256, 256)):\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_png(image, channels=3)\n",
    "        image = tf.image.resize(image, img_size, method=tf.image.ResizeMethod.BILINEAR)\n",
    "        image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "        # --- Process Mask ---\n",
    "        mask = tf.io.read_file(mask_path)\n",
    "        mask = tf.image.decode_png(mask, channels=1)\n",
    "        mask = tf.image.resize(mask, img_size, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        mask = tf.cast(mask, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "        mask = tf.where(mask > 0.5, 1.0, 0.0)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    # Splitting the Dataset\n",
    "    num_files = len(image_files)\n",
    "    print(f\"Found {num_files} image-mask pairs.\")\n",
    "\n",
    "    # 80% train, 10% validation, 10% test.\n",
    "    train_split = int(0.8 * num_files)\n",
    "    val_split   = int(0.9 * num_files)\n",
    "\n",
    "    train_image_files = image_files[:train_split]\n",
    "    train_mask_files  = mask_files[:train_split]\n",
    "\n",
    "    val_image_files = image_files[train_split:val_split]\n",
    "    val_mask_files  = mask_files[train_split:val_split]\n",
    "\n",
    "    test_image_files = image_files[val_split:]\n",
    "    test_mask_files  = mask_files[val_split:]\n",
    "\n",
    "    # Create tf.data Datasets\n",
    "    batch_size = 8\n",
    "\n",
    "    def create_dataset(img_files, msk_files, batch_size):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((img_files, msk_files))\n",
    "        dataset = dataset.map(lambda img, msk: process_path(img, msk),\n",
    "                            num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        dataset = dataset.shuffle(buffer_size=100)\n",
    "        dataset = dataset.batch(batch_size)\n",
    "        return dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    train_ds = create_dataset(train_image_files, train_mask_files, batch_size)\n",
    "    val_ds   = create_dataset(val_image_files, val_mask_files, batch_size)\n",
    "    test_ds  = create_dataset(test_image_files, test_mask_files, batch_size)\n",
    "\n",
    "    # Model Compilation\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "                loss=\"binary_crossentropy\",\n",
    "                metrics=[\"accuracy\", iou, dice, precision, recall])\n",
    "\n",
    "    # Callbacks Setup\n",
    "    checkpoint_cb = ModelCheckpoint(\"best_model.h5\", save_best_only=True,\n",
    "                                    monitor=\"val_loss\", mode=\"min\")\n",
    "    tensorboard_cb = TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "    # Training the Model\n",
    "    epochs = 50\n",
    "    history = model.fit(train_ds,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=val_ds,\n",
    "                        callbacks=[checkpoint_cb, tensorboard_cb])\n",
    "\n",
    "    # Evaluating the Model on Test Data\n",
    "    test_results = model.evaluate(test_ds)\n",
    "    print(\"\\nTest Results:\")\n",
    "    for name, value in zip(model.metrics_names, test_results):\n",
    "        print(f\"{name}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "\n",
    "\n",
    "def iou(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"Intersection over Union (IoU) metric.\"\"\"\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true + y_pred, axis=[1, 2, 3]) - intersection\n",
    "    return tf.reduce_mean((intersection + smooth) / (union + smooth))\n",
    "\n",
    "def dice(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"Dice coefficient (DSC) metric.\"\"\"\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    return tf.reduce_mean((2. * intersection + smooth) /\n",
    "                          (tf.reduce_sum(y_true, axis=[1, 2, 3]) +\n",
    "                           tf.reduce_sum(y_pred, axis=[1, 2, 3]) + smooth))\n",
    "\n",
    "def precision(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"Precision metric.\"\"\"\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    true_positives = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    predicted_positives = tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    return tf.reduce_mean(true_positives / (predicted_positives + smooth))\n",
    "\n",
    "def recall(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"Recall metric.\"\"\"\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    true_positives = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    actual_positives = tf.reduce_sum(y_true, axis=[1, 2, 3])\n",
    "    return tf.reduce_mean(true_positives / (actual_positives + smooth))\n",
    "\n",
    "\n",
    "# Again defining the model, first we analyzed now we will use it to train\n",
    "def light_unet(input_shape=(256, 256, 3)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # -------- Encoder --------\n",
    "    x1 = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x1 = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(x1)\n",
    "\n",
    "    x2 = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(p1)\n",
    "    x2 = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(x2)\n",
    "\n",
    "    x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(p2)\n",
    "    x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "\n",
    "    # -------- Decoder --------\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Concatenate()([x, x2])\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Concatenate()([x, x1])\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "\n",
    "    # -------- Output --------\n",
    "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "model = light_unet()\n",
    "model.summary()\n",
    "\n",
    "# Data Loading and Preprocessing\n",
    "image_dir = r\"D:\\Downloads\\MTP-2\\unified_dataset\\images\"\n",
    "mask_dir  = r\"D:\\Downloads\\MTP-2\\unified_dataset\\masks\"\n",
    "\n",
    "image_files = sorted(glob.glob(os.path.join(image_dir, \"*.png\")))\n",
    "mask_files  = sorted(glob.glob(os.path.join(mask_dir, \"*.png\")))\n",
    "\n",
    "if len(image_files) != len(mask_files):\n",
    "    raise ValueError(\"The number of images and masks does not match. Check your dataset.\")\n",
    "\n",
    "def process_path(image_path, mask_path, img_size=(256, 256)):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, img_size, method=tf.image.ResizeMethod.BILINEAR)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    # --- Process Mask ---\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, img_size, method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    mask = tf.cast(mask, tf.float32) / 255.0  # Normalize to [0, 1]\n",
    "    mask = tf.where(mask > 0.5, 1.0, 0.0)\n",
    "\n",
    "    return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Make sure to include your custom metrics in custom_objects\n",
    "custom_objects = {\n",
    "    'iou': iou,\n",
    "    'dice': dice,\n",
    "    'precision': precision,\n",
    "    'recall': recall\n",
    "}\n",
    "saved_model = load_model(\"best_model.h5\", custom_objects=custom_objects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting the Dataset\n",
    "num_files = len(image_files)\n",
    "print(f\"Found {num_files} image-mask pairs.\")\n",
    "\n",
    "# 80% train, 10% validation, 10% test.\n",
    "train_split = int(0.8 * num_files)\n",
    "val_split   = int(0.9 * num_files)\n",
    "\n",
    "train_image_files = image_files[:train_split]\n",
    "train_mask_files  = mask_files[:train_split]\n",
    "\n",
    "val_image_files = image_files[train_split:val_split]\n",
    "val_mask_files  = mask_files[train_split:val_split]\n",
    "\n",
    "test_image_files = image_files[val_split:]\n",
    "test_mask_files  = mask_files[val_split:]\n",
    "\n",
    "# Create tf.data Datasets\n",
    "batch_size = 8\n",
    "\n",
    "def create_dataset(img_files, msk_files, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_files, msk_files))\n",
    "    dataset = dataset.map(lambda img, msk: process_path(img, msk),\n",
    "                          num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=100)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = create_dataset(train_image_files, train_mask_files, batch_size)\n",
    "val_ds   = create_dataset(val_image_files, val_mask_files, batch_size)\n",
    "test_ds  = create_dataset(test_image_files, test_mask_files, batch_size)\n",
    "\n",
    "# Model Compilation\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\", iou, dice, precision, recall])\n",
    "\n",
    "# Callbacks Setup\n",
    "checkpoint_cb = ModelCheckpoint(\"best_model.h5\", save_best_only=True,\n",
    "                                monitor=\"val_loss\", mode=\"min\")\n",
    "tensorboard_cb = TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "\n",
    "test_results = saved_model.evaluate(test_ds)\n",
    "print(\"\\nTest Results:\")\n",
    "for name, value in zip(saved_model.metrics_names, test_results):\n",
    "    print(f\"{name}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def iou(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true + y_pred, axis=[1, 2, 3]) - intersection\n",
    "    return tf.reduce_mean((intersection + smooth) / (union + smooth))\n",
    "\n",
    "def dice(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    return tf.reduce_mean((2. * intersection + smooth) /\n",
    "                          (tf.reduce_sum(y_true, axis=[1, 2, 3]) +\n",
    "                           tf.reduce_sum(y_pred, axis=[1, 2, 3]) + smooth))\n",
    "\n",
    "def precision(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    true_positives = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    predicted_positives = tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    return tf.reduce_mean(true_positives / (predicted_positives + smooth))\n",
    "\n",
    "def recall(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    true_positives = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    actual_positives = tf.reduce_sum(y_true, axis=[1, 2, 3])\n",
    "    return tf.reduce_mean(true_positives / (actual_positives + smooth))\n",
    "\n",
    "custom_objects = {\n",
    "    'iou': iou,\n",
    "    'dice': dice,\n",
    "    'precision': precision,\n",
    "    'recall': recall\n",
    "}\n",
    "saved_model = load_model(\"best_model.h5\", custom_objects=custom_objects)\n",
    "saved_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                    loss=\"binary_crossentropy\",\n",
    "                    metrics=[\"accuracy\", iou, dice, precision, recall])\n",
    "\n",
    "class CustomPruningCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, pruning_percent=0.5):\n",
    "        super(CustomPruningCallback, self).__init__()\n",
    "        self.pruning_percent = pruning_percent\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nPruning weights after epoch {epoch + 1}\")\n",
    "        for layer in self.model.layers:\n",
    "            if hasattr(layer, 'kernel'):\n",
    "                weights = layer.kernel.numpy()\n",
    "                threshold = np.percentile(np.abs(weights), self.pruning_percent * 100)\n",
    "                pruned_weights = np.where(np.abs(weights) < threshold, 0, weights)\n",
    "                layer.kernel.assign(pruned_weights)\n",
    "                print(f\"Layer '{layer.name}': pruned weights with |value| < {threshold:.4f}\")\n",
    "\n",
    "pruning_callback = CustomPruningCallback(pruning_percent=0.5)\n",
    "saved_model.fit(train_ds, epochs=5, validation_data=val_ds, callbacks=[pruning_callback])\n",
    "saved_model.save(\"pruned_model.h5\")\n",
    "\n",
    "def simulate_quantization(model, bit_width, quantization_type='int'):\n",
    "    if bit_width == 32:\n",
    "        cloned = tf.keras.models.clone_model(model)\n",
    "        cloned.set_weights(model.get_weights())\n",
    "        return cloned\n",
    "    cloned_model = tf.keras.models.clone_model(model)\n",
    "    cloned_model.set_weights(model.get_weights())\n",
    "    for layer in cloned_model.layers:\n",
    "        for attr in ['kernel', 'bias']:\n",
    "            if hasattr(layer, attr):\n",
    "                weight_var = getattr(layer, attr)\n",
    "                w = weight_var.numpy()\n",
    "                if np.all(w == 0):\n",
    "                    continue\n",
    "                q_levels = 2 ** bit_width\n",
    "                if quantization_type == 'int':\n",
    "                    max_abs = np.max(np.abs(w))\n",
    "                    if max_abs == 0:\n",
    "                        continue\n",
    "                    scale = max_abs / ((q_levels / 2) - 1)\n",
    "                    quantized = np.clip(np.round(w / scale), -q_levels/2, q_levels/2 - 1)\n",
    "                    dequantized = quantized * scale\n",
    "                elif quantization_type == 'float':\n",
    "                    w_min = w.min()\n",
    "                    w_max = w.max()\n",
    "                    if w_max - w_min == 0:\n",
    "                        continue\n",
    "                    scale = (w_max - w_min) / (q_levels - 1)\n",
    "                    quantized = np.round((w - w_min) / scale)\n",
    "                    dequantized = quantized * scale + w_min\n",
    "                weight_var.assign(dequantized)\n",
    "    return cloned_model\n",
    "\n",
    "bit_widths = [32, 16, 8, 4, 2]\n",
    "quantization_types = ['float', 'int']\n",
    "quantization_results = {}\n",
    "for q_type in quantization_types:\n",
    "    for bits in bit_widths:\n",
    "        print(f\"\\nSimulating {q_type} quantization with {bits} bits...\")\n",
    "        quant_model = simulate_quantization(saved_model, bit_width=bits, quantization_type=q_type)\n",
    "        quant_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                            loss=\"binary_crossentropy\",\n",
    "                            metrics=[\"accuracy\", iou, dice, precision, recall])\n",
    "        results = quant_model.evaluate(test_ds, verbose=0)\n",
    "        metrics_dict = dict(zip(quant_model.metrics_names, results))\n",
    "        quantization_results[f\"{q_type}_{bits}\"] = metrics_dict\n",
    "        print(f\"Results for {q_type} quantization at {bits} bits: {metrics_dict}\")\n",
    "        quant_model.save(f\"quantized_model_{q_type}_{bits}.h5\")\n",
    "\n",
    "print(\"\\nSummary of Quantization Results:\")\n",
    "for variant, metrics in quantization_results.items():\n",
    "    print(f\"{variant}: {metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, clone_model\n",
    "\n",
    "# ----- Explanation -----\n",
    "# Pruning removes weights that are considered unimportant (typically those with small magnitude),\n",
    "# thereby reducing the effective number of parameters.\n",
    "#\n",
    "# Quantization converts model weights (and sometimes activations) from high precision (32-bit float)\n",
    "# to lower precision (such as 16-bit float or 8-bit integer). This reduces model size and can speed up inference.\n",
    "#\n",
    "# For example, float16 quantization preserves dynamic range with half the memory, while integer\n",
    "# quantization maps values to a fixed integer range (e.g., -128 to 127 for 8-bit) often with some calibration.\n",
    "#\n",
    "# In this example, we perform float16 quantization using TFLite conversion.\n",
    "\n",
    "# ----- Custom Metrics Definitions -----\n",
    "def iou(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    inter = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = tf.reduce_sum(y_true + y_pred, axis=[1,2,3]) - inter\n",
    "    return tf.reduce_mean((inter + smooth) / (union + smooth))\n",
    "\n",
    "def dice(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    inter = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    return tf.reduce_mean((2 * inter + smooth) / (tf.reduce_sum(y_true, axis=[1,2,3]) +\n",
    "                                                  tf.reduce_sum(y_pred, axis=[1,2,3]) + smooth))\n",
    "\n",
    "def precision(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    tp = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    pp = tf.reduce_sum(y_pred, axis=[1,2,3])\n",
    "    return tf.reduce_mean(tp / (pp + smooth))\n",
    "\n",
    "def recall(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    tp = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    ap = tf.reduce_sum(y_true, axis=[1,2,3])\n",
    "    return tf.reduce_mean(tp / (ap + smooth))\n",
    "\n",
    "custom_objects = {'iou': iou, 'dice': dice, 'precision': precision, 'recall': recall}\n",
    "\n",
    "# ----- Load and Evaluate the Original Model -----\n",
    "model = load_model(\"best_model.h5\", custom_objects=custom_objects)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\", iou, dice, precision, recall])\n",
    "\n",
    "# Print the dtype of the first layer that has weights (skipping layers like Input)\n",
    "found = False\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if weights:\n",
    "        print(\"Layer '{}' weight dtype: {}\".format(layer.name, weights[0].dtype))\n",
    "        found = True\n",
    "        break\n",
    "if not found:\n",
    "    print(\"No layer with weights found.\")\n",
    "\n",
    "orig_results = model.evaluate(test_ds, verbose=1)\n",
    "print(\"\\nOriginal Model Metrics:\")\n",
    "print(\"Loss: {:.4f}, Accuracy: {:.4f}, IoU: {:.4f}, Dice: {:.4f}, Precision: {:.4f}, Recall: {:.4f}\".format(\n",
    "    orig_results[0], orig_results[1], orig_results[2], orig_results[3], orig_results[4], orig_results[5]))\n",
    "\n",
    "# ----- Convert the Model to TFLite with Float16 Quantization -----\n",
    "cloned_model = clone_model(model)\n",
    "cloned_model.set_weights(model.get_weights())\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(cloned_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_model = converter.convert()\n",
    "with open(\"model_float16.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "print(\"\\nFloat16 quantized TFLite model saved as 'model_float16.tflite'.\")\n",
    "\n",
    "# ----- Evaluate the TFLite Quantized Model on the Test Dataset -----\n",
    "def evaluate_tflite_model(tflite_model, test_ds):\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    # Get expected input shape; typically something like [1, height, width, channels]\n",
    "    expected_shape = input_details[0]['shape']\n",
    "    batch_expected = expected_shape[0]\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_ground_truth = []\n",
    "    \n",
    "    for images, masks in test_ds:\n",
    "        images_np = images.numpy()\n",
    "        masks_np = masks.numpy()\n",
    "        # If batch size from test_ds differs from expected, iterate sample by sample.\n",
    "        if images_np.shape[0] != batch_expected:\n",
    "            for i in range(images_np.shape[0]):\n",
    "                sample = np.expand_dims(images_np[i], axis=0)\n",
    "                interpreter.set_tensor(input_details[0]['index'], sample)\n",
    "                interpreter.invoke()\n",
    "                pred = interpreter.get_tensor(output_details[0]['index'])\n",
    "                all_predictions.append(pred[0])\n",
    "                all_ground_truth.append(masks_np[i])\n",
    "        else:\n",
    "            interpreter.set_tensor(input_details[0]['index'], images_np)\n",
    "            interpreter.invoke()\n",
    "            preds = interpreter.get_tensor(output_details[0]['index'])\n",
    "            all_predictions.append(preds)\n",
    "            all_ground_truth.append(masks_np)\n",
    "    \n",
    "    all_predictions = np.concatenate([p if p.ndim==4 else np.expand_dims(p,0) for p in all_predictions], axis=0)\n",
    "    all_ground_truth = np.concatenate([g if g.ndim==4 else np.expand_dims(g,0) for g in all_ground_truth], axis=0)\n",
    "    \n",
    "    binary_preds = (all_predictions > 0.5).astype(np.float32)\n",
    "    accuracy = np.mean(binary_preds == all_ground_truth)\n",
    "    intersection = np.sum(all_ground_truth * binary_preds)\n",
    "    union = np.sum(all_ground_truth) + np.sum(binary_preds) - intersection\n",
    "    iou_val = (intersection + 1e-6) / (union + 1e-6)\n",
    "    dice_val = (2 * intersection + 1e-6) / (np.sum(all_ground_truth) + np.sum(binary_preds) + 1e-6)\n",
    "    return accuracy, iou_val, dice_val\n",
    "\n",
    "acc_tflite, iou_tflite, dice_tflite = evaluate_tflite_model(tflite_model, test_ds)\n",
    "print(\"\\nTFLite Float16 Quantized Model Metrics:\")\n",
    "print(\"Accuracy: {:.4f}, IoU: {:.4f}, Dice: {:.4f}\".format(acc_tflite, iou_tflite, dice_tflite))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, clone_model\n",
    "\n",
    "# ----- Explanation -----\n",
    "# Pruning removes (zeros out) weights with small magnitudes (unimportant weights),\n",
    "# reducing the effective number of parameters.\n",
    "#\n",
    "# Quantization converts weights and activations from high precision (32-bit float)\n",
    "# into lower precision. For example, float16 quantization reduces memory usage while\n",
    "# preserving dynamic range, and integer (e.g., int8) quantization maps values to a fixed\n",
    "# range (e.g., -128 to 127), which can further reduce model size and speed up inference.\n",
    "#\n",
    "# In the code below, we convert the model to TFLite models with:\n",
    "#   - Native int8 quantization (which requires a representative dataset).\n",
    "#   - Native float16 quantization.\n",
    "#   - Custom simulated 4-bit and 2-bit quantization (by rounding weights to fewer levels).\n",
    "\n",
    "# ----- Custom Metrics -----\n",
    "def iou(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    inter = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = tf.reduce_sum(y_true + y_pred, axis=[1,2,3]) - inter\n",
    "    return tf.reduce_mean((inter + smooth) / (union + smooth))\n",
    "\n",
    "def dice(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    inter = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    return tf.reduce_mean((2 * inter + smooth) / (tf.reduce_sum(y_true, axis=[1,2,3]) +\n",
    "                                                  tf.reduce_sum(y_pred, axis=[1,2,3]) + smooth))\n",
    "\n",
    "def precision(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    tp = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    pp = tf.reduce_sum(y_pred, axis=[1,2,3])\n",
    "    return tf.reduce_mean(tp / (pp + smooth))\n",
    "\n",
    "def recall(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    tp = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    ap = tf.reduce_sum(y_true, axis=[1,2,3])\n",
    "    return tf.reduce_mean(tp / (ap + smooth))\n",
    "\n",
    "custom_objects = {'iou': iou, 'dice': dice, 'precision': precision, 'recall': recall}\n",
    "\n",
    "# ----- Load and Evaluate the Original Model -----\n",
    "model = load_model(\"best_model.h5\", custom_objects=custom_objects)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\", iou, dice, precision, recall])\n",
    "\n",
    "found = False\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if weights:\n",
    "        print(f\"Layer '{layer.name}' weight dtype: {weights[0].dtype}\")\n",
    "        found = True\n",
    "        break\n",
    "if not found:\n",
    "    print(\"No layer with weights found.\")\n",
    "\n",
    "orig_results = model.evaluate(test_ds, verbose=1)\n",
    "print(\"\\nOriginal Model Metrics:\")\n",
    "print(\"Loss: {:.4f}, Accuracy: {:.4f}, IoU: {:.4f}, Dice: {:.4f}, Precision: {:.4f}, Recall: {:.4f}\".format(\n",
    "    orig_results[0], orig_results[1], orig_results[2], orig_results[3], orig_results[4], orig_results[5]))\n",
    "\n",
    "def convert_to_tflite_int8(model, representative_data):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8\n",
    "    converter.inference_output_type = tf.int8\n",
    "    return converter.convert()\n",
    "\n",
    "def convert_to_tflite_float16(model):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "    return converter.convert()\n",
    "\n",
    "def custom_quantize_model(model, bit_width):\n",
    "    cloned_model = clone_model(model)\n",
    "    cloned_model.set_weights(model.get_weights())\n",
    "    for layer in cloned_model.layers:\n",
    "        for attr in ['kernel', 'bias']:\n",
    "            if hasattr(layer, attr):\n",
    "                w = getattr(layer, attr).numpy()\n",
    "                if np.all(w == 0):\n",
    "                    continue\n",
    "                w_min = w.min()\n",
    "                w_max = w.max()\n",
    "                q_levels = 2 ** bit_width\n",
    "                if w_max == w_min:\n",
    "                    continue\n",
    "                scale = (w_max - w_min) / (q_levels - 1)\n",
    "                q = np.round((w - w_min) / scale)\n",
    "                w_quant = q * scale + w_min\n",
    "                getattr(layer, attr).assign(w_quant)\n",
    "    return cloned_model\n",
    "\n",
    "def convert_custom_to_tflite(model):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    return converter.convert()\n",
    "\n",
    "def representative_data_gen():\n",
    "    for images, _ in test_ds.take(100):\n",
    "        yield [images.numpy()]\n",
    "\n",
    "# ----- Convert Models -----\n",
    "# Int8 quantization\n",
    "tflite_int8 = convert_to_tflite_int8(model, representative_data_gen)\n",
    "with open(\"model_int8.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_int8)\n",
    "print(\"\\nInt8 quantized TFLite model saved as 'model_int8.tflite'.\")\n",
    "\n",
    "# Float16 quantization\n",
    "tflite_float16 = convert_to_tflite_float16(model)\n",
    "with open(\"model_float16.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_float16)\n",
    "print(\"Float16 quantized TFLite model saved as 'model_float16.tflite'.\")\n",
    "\n",
    "# Custom 4-bit quantization\n",
    "model_4bit = custom_quantize_model(model, 4)\n",
    "tflite_4bit = convert_custom_to_tflite(model_4bit)\n",
    "with open(\"model_4bit.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_4bit)\n",
    "print(\"Custom 4-bit quantized TFLite model saved as 'model_4bit.tflite'.\")\n",
    "\n",
    "# Custom 2-bit quantization\n",
    "model_2bit = custom_quantize_model(model, 2)\n",
    "tflite_2bit = convert_custom_to_tflite(model_2bit)\n",
    "with open(\"model_2bit.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_2bit)\n",
    "print(\"Custom 2-bit quantized TFLite model saved as 'model_2bit.tflite'.\")\n",
    " \n",
    "def evaluate_tflite_model(tflite_model, test_ds):\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details() \n",
    "    expected_dtype = input_details[0]['dtype']\n",
    "    quant_params = input_details[0].get('quantization', (1.0, 0))\n",
    "    scale, zero_point = quant_params\n",
    "\n",
    "    all_preds = []\n",
    "    all_gts = [] \n",
    "    for images, masks in test_ds:\n",
    "        images_np = images.numpy()\n",
    "        masks_np = masks.numpy() \n",
    "        if expected_dtype == np.int8:\n",
    "            images_np = np.round(images_np / scale) + zero_point\n",
    "            images_np = images_np.astype(np.int8) \n",
    "        batch_size = images_np.shape[0]\n",
    "        for i in range(batch_size):\n",
    "            sample = np.expand_dims(images_np[i], axis=0)\n",
    "            interpreter.set_tensor(input_details[0]['index'], sample)\n",
    "            interpreter.invoke()\n",
    "            pred = interpreter.get_tensor(output_details[0]['index'])\n",
    "            all_preds.append(pred[0])\n",
    "            all_gts.append(masks_np[i])\n",
    "    all_preds = np.concatenate([p if p.ndim==4 else np.expand_dims(p, 0) for p in all_preds], axis=0)\n",
    "    all_gts = np.concatenate([g if g.ndim==4 else np.expand_dims(g, 0) for g in all_gts], axis=0)\n",
    "    binary_preds = (all_preds > 0.5).astype(np.float32)\n",
    "    accuracy = np.mean(binary_preds == all_gts)\n",
    "    intersection = np.sum(all_gts * binary_preds)\n",
    "    union = np.sum(all_gts) + np.sum(binary_preds) - intersection\n",
    "    iou_val = (intersection + 1e-6) / (union + 1e-6)\n",
    "    dice_val = (2 * intersection + 1e-6) / (np.sum(all_gts) + np.sum(binary_preds) + 1e-6)\n",
    "    return accuracy, iou_val, dice_val\n",
    " \n",
    "print(\"\\nEvaluating TFLite Models:\")\n",
    "\n",
    "acc_int8, iou_int8, dice_int8 = evaluate_tflite_model(tflite_int8, test_ds)\n",
    "print(\"Int8 Model Metrics: Accuracy: {:.4f}, IoU: {:.4f}, Dice: {:.4f}\".format(acc_int8, iou_int8, dice_int8))\n",
    "\n",
    "acc_float16, iou_float16, dice_float16 = evaluate_tflite_model(tflite_float16, test_ds)\n",
    "print(\"Float16 Model Metrics: Accuracy: {:.4f}, IoU: {:.4f}, Dice: {:.4f}\".format(acc_float16, iou_float16, dice_float16))\n",
    "\n",
    "acc_4bit, iou_4bit, dice_4bit = evaluate_tflite_model(tflite_4bit, test_ds)\n",
    "print(\"Custom 4-bit Model Metrics: Accuracy: {:.4f}, IoU: {:.4f}, Dice: {:.4f}\".format(acc_4bit, iou_4bit, dice_4bit))\n",
    "\n",
    "acc_2bit, iou_2bit, dice_2bit = evaluate_tflite_model(tflite_2bit, test_ds)\n",
    "print(\"Custom 2-bit Model Metrics: Accuracy: {:.4f}, IoU: {:.4f}, Dice: {:.4f}\".format(acc_2bit, iou_2bit, dice_2bit))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating TFLite Models\n",
    "\n",
    "| Model                  | Accuracy | IoU   | Dice  |\n",
    "|------------------------|----------|-------|-------|\n",
    "| Int8 Model            | 0.9634   | 0.7293 | 0.8435 |\n",
    "| Float16 Model         | 0.9637   | 0.7327 | 0.8458 |\n",
    "| Custom 4-bit Model    | 0.9614   | 0.7100 | 0.8304 |\n",
    "| Custom 2-bit Model    | 0.2311   | 0.0947 | 0.1730 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, clone_model\n",
    "\n",
    "def iou(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    inter = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = tf.reduce_sum(y_true + y_pred, axis=[1,2,3]) - inter\n",
    "    return tf.reduce_mean((inter + smooth) / (union + smooth))\n",
    "\n",
    "def dice(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    inter = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    return tf.reduce_mean((2 * inter + smooth) / (tf.reduce_sum(y_true, axis=[1,2,3]) + tf.reduce_sum(y_pred, axis=[1,2,3]) + smooth))\n",
    "\n",
    "def precision(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    tp = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    pp = tf.reduce_sum(y_pred, axis=[1,2,3])\n",
    "    return tf.reduce_mean(tp / (pp + smooth))\n",
    "\n",
    "def recall(y_true, y_pred, smooth=1e-6):\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "    tp = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
    "    ap = tf.reduce_sum(y_true, axis=[1,2,3])\n",
    "    return tf.reduce_mean(tp / (ap + smooth))\n",
    "\n",
    "custom_objects = {'iou': iou, 'dice': dice, 'precision': precision, 'recall': recall}\n",
    "model = load_model(\"best_model.h5\", custom_objects=custom_objects)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\", iou, dice, precision, recall])\n",
    "found = False\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if weights:\n",
    "        print(f\"Layer '{layer.name}' weight dtype: {weights[0].dtype}\")\n",
    "        found = True\n",
    "        break\n",
    "if not found:\n",
    "    print(\"No layer with weights found.\")\n",
    "orig_eval = model.evaluate(test_ds, verbose=1)\n",
    "orig_metrics = {\"Loss\": orig_eval[0], \"Accuracy\": orig_eval[1], \"IoU\": orig_eval[2], \"Dice\": orig_eval[3], \"Precision\": orig_eval[4], \"Recall\": orig_eval[5]}\n",
    "print(\"\\nOriginal Model (Keras) Metrics:\")\n",
    "for k, v in orig_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "def prune_model(model, pruning_percent=0.5):\n",
    "    pruned_model = clone_model(model)\n",
    "    pruned_model.set_weights(model.get_weights())\n",
    "    for layer in pruned_model.layers:\n",
    "        if hasattr(layer, 'kernel'):\n",
    "            w = layer.kernel.numpy()\n",
    "            threshold = np.percentile(np.abs(w), pruning_percent * 100)\n",
    "            pruned_w = np.where(np.abs(w) < threshold, 0, w)\n",
    "            layer.kernel.assign(pruned_w)\n",
    "    return pruned_model\n",
    "pruned_model = prune_model(model, pruning_percent=0.5)\n",
    "pruned_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                     loss=\"binary_crossentropy\",\n",
    "                     metrics=[\"accuracy\", iou, dice, precision, recall])\n",
    "pruned_eval = pruned_model.evaluate(test_ds, verbose=1)\n",
    "pruned_metrics = {\"Loss\": pruned_eval[0], \"Accuracy\": pruned_eval[1], \"IoU\": pruned_eval[2], \"Dice\": pruned_eval[3], \"Precision\": pruned_eval[4], \"Recall\": pruned_eval[5]}\n",
    "print(\"\\nPruned Model (Keras) Metrics:\")\n",
    "for k, v in pruned_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "def convert_to_tflite_int8(model, representative_data):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_data\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8\n",
    "    converter.inference_output_type = tf.int8\n",
    "    return converter.convert()\n",
    "def convert_to_tflite_float16(model):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "    return converter.convert()\n",
    "def custom_quantize_model(model, bit_width):\n",
    "    cloned_model = clone_model(model)\n",
    "    cloned_model.set_weights(model.get_weights())\n",
    "    for layer in cloned_model.layers:\n",
    "        for attr in ['kernel', 'bias']:\n",
    "            if hasattr(layer, attr):\n",
    "                w = getattr(layer, attr).numpy()\n",
    "                if np.all(w == 0):\n",
    "                    continue\n",
    "                w_min = w.min()\n",
    "                w_max = w.max()\n",
    "                q_levels = 2 ** bit_width\n",
    "                if w_max == w_min:\n",
    "                    continue\n",
    "                scale = (w_max - w_min) / (q_levels - 1)\n",
    "                q = np.round((w - w_min) / scale)\n",
    "                w_quant = q * scale + w_min\n",
    "                getattr(layer, attr).assign(w_quant)\n",
    "    return cloned_model\n",
    "def convert_custom_to_tflite(model):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    return converter.convert()\n",
    "def representative_data_gen():\n",
    "    for images, _ in test_ds.take(100):\n",
    "        yield [images.numpy()]\n",
    "orig_tflite_int8 = convert_to_tflite_int8(model, representative_data_gen)\n",
    "orig_tflite_float16 = convert_to_tflite_float16(model)\n",
    "orig_model_4bit = custom_quantize_model(model, 4)\n",
    "orig_tflite_4bit = convert_custom_to_tflite(orig_model_4bit)\n",
    "orig_model_2bit = custom_quantize_model(model, 2)\n",
    "orig_tflite_2bit = convert_custom_to_tflite(orig_model_2bit)\n",
    "pruned_tflite_int8 = convert_to_tflite_int8(pruned_model, representative_data_gen)\n",
    "pruned_tflite_float16 = convert_to_tflite_float16(pruned_model)\n",
    "pruned_model_4bit = custom_quantize_model(pruned_model, 4)\n",
    "pruned_tflite_4bit = convert_custom_to_tflite(pruned_model_4bit)\n",
    "pruned_model_2bit = custom_quantize_model(pruned_model, 2)\n",
    "pruned_tflite_2bit = convert_custom_to_tflite(pruned_model_2bit)\n",
    "with open(\"orig_int8.tflite\", \"wb\") as f: f.write(orig_tflite_int8)\n",
    "with open(\"orig_float16.tflite\", \"wb\") as f: f.write(orig_tflite_float16)\n",
    "with open(\"orig_4bit.tflite\", \"wb\") as f: f.write(orig_tflite_4bit)\n",
    "with open(\"orig_2bit.tflite\", \"wb\") as f: f.write(orig_tflite_2bit)\n",
    "with open(\"pruned_int8.tflite\", \"wb\") as f: f.write(pruned_tflite_int8)\n",
    "with open(\"pruned_float16.tflite\", \"wb\") as f: f.write(pruned_tflite_float16)\n",
    "with open(\"pruned_4bit.tflite\", \"wb\") as f: f.write(pruned_tflite_4bit)\n",
    "with open(\"pruned_2bit.tflite\", \"wb\") as f: f.write(pruned_tflite_2bit)\n",
    "def evaluate_tflite_model(tflite_model, test_ds):\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    expected_dtype = input_details[0]['dtype']\n",
    "    quant_params = input_details[0].get('quantization', (1.0, 0))\n",
    "    scale, zero_point = quant_params\n",
    "    all_preds = []\n",
    "    all_gts = []\n",
    "    for images, masks in test_ds:\n",
    "        images_np = images.numpy()\n",
    "        masks_np = masks.numpy()\n",
    "        if expected_dtype == np.int8:\n",
    "            images_np = np.round(images_np / scale) + zero_point\n",
    "            images_np = images_np.astype(np.int8)\n",
    "        batch_size = images_np.shape[0]\n",
    "        for i in range(batch_size):\n",
    "            sample = np.expand_dims(images_np[i], axis=0)\n",
    "            interpreter.set_tensor(input_details[0]['index'], sample)\n",
    "            interpreter.invoke()\n",
    "            pred = interpreter.get_tensor(output_details[0]['index'])\n",
    "            all_preds.append(pred[0])\n",
    "            all_gts.append(masks_np[i])\n",
    "    all_preds = np.concatenate([p if p.ndim==4 else np.expand_dims(p,0) for p in all_preds], axis=0)\n",
    "    all_gts = np.concatenate([g if g.ndim==4 else np.expand_dims(g,0) for g in all_gts], axis=0)\n",
    "    binary_preds = (all_preds > 0.5).astype(np.float32)\n",
    "    accuracy = np.mean(binary_preds == all_gts)\n",
    "    intersection = np.sum(all_gts * binary_preds)\n",
    "    union = np.sum(all_gts) + np.sum(binary_preds) - intersection\n",
    "    iou_val = (intersection + 1e-6) / (union + 1e-6)\n",
    "    dice_val = (2 * intersection + 1e-6) / (np.sum(all_gts) + np.sum(binary_preds) + 1e-6)\n",
    "    return accuracy, iou_val, dice_val\n",
    "results = {}\n",
    "results[\"Orig Int8\"] = dict(zip([\"Accuracy\", \"IoU\", \"Dice\"], evaluate_tflite_model(orig_tflite_int8, test_ds)))\n",
    "results[\"Orig Float16\"] = dict(zip([\"Accuracy\", \"IoU\", \"Dice\"], evaluate_tflite_model(orig_tflite_float16, test_ds)))\n",
    "results[\"Orig 4bit\"] = dict(zip([\"Accuracy\", \"IoU\", \"Dice\"], evaluate_tflite_model(orig_tflite_4bit, test_ds)))\n",
    "results[\"Orig 2bit\"] = dict(zip([\"Accuracy\", \"IoU\", \"Dice\"], evaluate_tflite_model(orig_tflite_2bit, test_ds)))\n",
    "results[\"Pruned Int8\"] = dict(zip([\"Accuracy\", \"IoU\", \"Dice\"], evaluate_tflite_model(pruned_tflite_int8, test_ds)))\n",
    "results[\"Pruned Float16\"] = dict(zip([\"Accuracy\", \"IoU\", \"Dice\"], evaluate_tflite_model(pruned_tflite_float16, test_ds)))\n",
    "results[\"Pruned 4bit\"] = dict(zip([\"Accuracy\", \"IoU\", \"Dice\"], evaluate_tflite_model(pruned_tflite_4bit, test_ds)))\n",
    "results[\"Pruned 2bit\"] = dict(zip([\"Accuracy\", \"IoU\", \"Dice\"], evaluate_tflite_model(pruned_tflite_2bit, test_ds)))\n",
    "print(\"\\n=== Keras Model Comparison ===\")\n",
    "print(\"{:<25} {:>8} {:>10} {:>10} {:>10}\".format(\"Variant\", \"Loss\", \"Accuracy\", \"IoU\", \"Dice\"))\n",
    "print(\"-\"*65)\n",
    "print(\"{:<25} {:>8.4f} {:>10.4f} {:>10.4f} {:>10.4f}\".format(\"Original (Keras)\",\n",
    "      orig_metrics[\"Loss\"], orig_metrics[\"Accuracy\"], orig_metrics[\"IoU\"], orig_metrics[\"Dice\"]))\n",
    "print(\"{:<25} {:>8.4f} {:>10.4f} {:>10.4f} {:>10.4f}\".format(\"Pruned (Keras)\",\n",
    "      pruned_metrics[\"Loss\"], pruned_metrics[\"Accuracy\"], pruned_metrics[\"IoU\"], pruned_metrics[\"Dice\"]))\n",
    "print(\"\\n=== TFLite Quantized Models Comparison ===\")\n",
    "print(\"{:<20} {:>10} {:>10} {:>10}\".format(\"Variant\", \"Accuracy\", \"IoU\", \"Dice\"))\n",
    "print(\"-\"*55)\n",
    "for variant, met in results.items():\n",
    "    print(\"{:<20} {:>10.4f} {:>10.4f} {:>10.4f}\".format(variant, met[\"Accuracy\"], met[\"IoU\"], met[\"Dice\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model Comparison\n",
    "\n",
    "| Variant            | Loss   | Accuracy | IoU   | Dice  |\n",
    "|--------------------|--------|----------|-------|-------|\n",
    "| Original (Keras)  | 0.1169 | 0.9637   | 0.7254 | 0.8051 |\n",
    "| Pruned (Keras)    | 0.1258 | 0.9588   | 0.6797 | 0.7662 |\n",
    "\n",
    "# TFLite Quantized Models Comparison\n",
    "\n",
    "| Variant          | Accuracy | IoU   | Dice  |\n",
    "|-----------------|----------|-------|-------|\n",
    "| Orig Int8       | 0.9634   | 0.7293 | 0.8435 |\n",
    "| Orig Float16    | 0.9637   | 0.7327 | 0.8458 |\n",
    "| Orig 4bit       | 0.9614   | 0.7100 | 0.8304 |\n",
    "| Orig 2bit       | 0.2311   | 0.0947 | 0.1730 |\n",
    "| Pruned Int8     | 0.9582   | 0.6876 | 0.8149 |\n",
    "| Pruned Float16  | 0.9588   | 0.6939 | 0.8193 |\n",
    "| Pruned 4bit     | 0.9409   | 0.5457 | 0.7061 |\n",
    "| Pruned 2bit     | 0.1256   | 0.1256 | 0.2232 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
